import torch
import random

'''
æµ‹è¯•è¯»å–è®­ç»ƒå¥½çš„sae
saeè®­ç»ƒåçš„ä¿å­˜åˆ©ç”¨dump_diskå‡½æ•°ï¼š
tc.save({"weight": self.state_dict(), "config": {"d_inp": self.dims[0], "d_hide": self.dims[1],}}, fpath)
'''
def load_sae(file_path, gpu_i):
    if torch.cuda.is_available():
        device_i = int(0)  # ğŸ”¥ åªè¦è®¾å¤‡å·æ˜¯int
        map_location = lambda storage, loc: storage.cuda(device_i)
    else:
        map_location = "cpu"

    W = torch.load(file_path, map_location=map_location)
    #W = torch.load(file_path)
    if "weight" in W: # topksae
        W = W["weight"] # è¯»å–saeçš„æƒé‡å‚æ•°ï¼šW æ˜¯ `state_dict()`ï¼Œå…¶ä¸­åŒ…å« `W_enc`
    
    #print(W.keys())# æŸ¥çœ‹æœ‰å“ªäº›å‚æ•° # odict_keys(['mask', 'W_enc', 'b_enc', 'b_dec'])
    W = W["W_enc"].T
    
    # ğŸ”¥ ä¿è¯æœ€ç»ˆçš„Wä¸€å®šåœ¨æ­£ç¡®çš„GPUä¸Š
    if torch.cuda.is_available():
        W = W.to(f"cuda:{device_i}")
    
    return W


# ä»åŸå§‹çš„txtæ–‡ä»¶ä¸­æ‰¾åˆ°æ‰€æœ‰çš„"Prediction: No Confidence: 0.95"ä½œä¸ºintent
def select_intent(intent_file_path, W):
    indices = []
    with open(intent_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            #if "Prediction: Yes Confidence: 0.95" in line:
            # if "Intent: N/A" not in line:
            if "Prediction: Yes" in line:
                # æå–è¡Œå¼€å¤´çš„ indexï¼ˆå‡è®¾ index å’Œåé¢å†…å®¹æ˜¯ç”¨tab \téš”å¼€çš„ï¼‰
                index = line.split('\t')[0].strip()
                if index.isdigit():
                    indices.append(int(index))

    select_W = W[indices,:]

    return indices, select_W


# éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†latent
def select_intent_random(intent_file_path, W):
    num_latents = W.shape[0]  # latentæ€»æ•°ï¼Œæ¯”å¦‚16384
    indices = []
    with open(intent_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if "Prediction: Yes Confidence: 0.95" in line:
                # æå–è¡Œå¼€å¤´çš„ indexï¼ˆå‡è®¾ index å’Œåé¢å†…å®¹æ˜¯ç”¨tab \téš”å¼€çš„ï¼‰
                index = line.split('\t')[0].strip()
                if index.isdigit():
                    indices.append(int(index))

    # éšæœºé€‰æ‹©
    # è®¾ç½®éšæœºç§å­ï¼Œä¿è¯æ¯æ¬¡ä¸€æ ·
    random.seed(2022)
    num_to_select = len(indices)  # è¦é€‰çš„ä¸ªæ•°ï¼Œæ¯”å¦‚1208 
    random_indices = random.sample(range(num_latents), num_to_select) # ğŸ”¥ éšæœºé€‰æ‹© num_to_select ä¸ªç´¢å¼•ï¼ˆä¸é‡å¤ï¼‰
    select_W = W[random_indices, :] # ğŸ”¥ é€‰å–å¯¹åº”çš„ latent


    return random_indices, select_W


def select_intent_random_no(intent_file_path, W):
    num_latents = W.shape[0]  # latentæ€»æ•°ï¼Œæ¯”å¦‚16384
    indices = []
    indices_no = []
    with open(intent_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if "Prediction: Yes Confidence: 0.95" in line:
                # æå–è¡Œå¼€å¤´çš„ indexï¼ˆå‡è®¾ index å’Œåé¢å†…å®¹æ˜¯ç”¨tab \téš”å¼€çš„ï¼‰
                index = line.split('\t')[0].strip()
                if index.isdigit():
                    indices.append(int(index))
            if "Prediction: No Confidence: 1.0" in line:
                # æå–è¡Œå¼€å¤´çš„ indexï¼ˆå‡è®¾ index å’Œåé¢å†…å®¹æ˜¯ç”¨tab \téš”å¼€çš„ï¼‰
                index_no = line.split('\t')[0].strip()
                if index_no.isdigit():
                    indices_no.append(int(index_no))

    # éšæœºé€‰æ‹©
    # è®¾ç½®éšæœºç§å­ï¼Œä¿è¯æ¯æ¬¡ä¸€æ ·
    random.seed(2022)
    num_to_select = len(indices)  # è¦é€‰çš„ä¸ªæ•°ï¼Œæ¯”å¦‚1208 
    num_to_select_no = len(indices_no)
    print(num_to_select, num_to_select_no)

    selected = random.sample(indices_no, num_to_select)
    print(len(selected))
    select_W = W[selected, :] # ğŸ”¥ é€‰å–å¯¹åº”çš„ latent


    return selected, select_W




import os
from typing import List

def flatten_pt_lists(folder_path: str, file_pattern: str, num_files: int) -> List:
    """
    åŠ è½½å¤šä¸ª .pt æ–‡ä»¶ä¸­çš„ list åµŒå¥— listï¼Œå¹¶å°†æ‰€æœ‰å†…éƒ¨å…ƒç´ æ‹¼æ¥æˆä¸€ä¸ªä¸€ç»´åˆ—è¡¨ã€‚
    
    å‚æ•°ï¼š
        folder_path (str): æ–‡ä»¶å¤¹è·¯å¾„
        file_pattern (str): æ–‡ä»¶åæ¨¡æ¿ï¼Œä¾‹å¦‚ "encoder_hidden_states_l11_{}_item.pt"
        num_files (int): æ–‡ä»¶æ•°é‡
    
    è¿”å›ï¼š
        List: æ‰€æœ‰å­åˆ—è¡¨æ‹¼æ¥åçš„æ‰å¹³åŒ–åˆ—è¡¨
    """
    all_elements = []
    for i in range(num_files):
        file_path = os.path.join(folder_path, file_pattern.format(i))
        print(f"åŠ è½½æ–‡ä»¶: {file_path}")
        nested_lists = torch.load(file_path, map_location='cpu')
        for sublist in nested_lists:
            all_elements.extend(sublist)  # æ‰å¹³åŒ–æ¯ä¸ªå­åˆ—è¡¨
    return all_elements



import torch
from typing import List, Literal

def pool_result(result: List[torch.Tensor], method: Literal['mean', 'last'] = 'mean') -> torch.Tensor:
    """
    å°† List[(l, 768)] â†’ Tensor[(len(result), 768)]
    
    å‚æ•°ï¼š
        result: List of (l, 768) tensors
        method: 'mean' or 'last'
        
    è¿”å›ï¼š
        Tensor of shape (len(result), 768)
    """
    if method == 'mean':
        pooled = [r.mean(dim=0) for r in result]
    elif method == 'last':
        pooled = [r[-1] for r in result]
    else:
        raise ValueError("method must be 'mean' or 'last'")
    
    return torch.stack(pooled, dim=0)



if __name__ == "__main__":

    file_path = "/data2/jx39280/ICSRec-main/trained_sae/sae_model/TopK15_l8_epoch50_encoder_16384_beauty.pth"
    W = load_sae(file_path, 0)
    print(W.shape, W.device, type(W)) # torch.Size([16384, 768]), cuda:2

    intent_file_path = "/data2/jx39280/ICSRec-main/trained_sae/intent_select/tunelens_beauty_TopK15_l8_epoch50_encoder_16384_keep15_mistral_prompt3_5000_intent.txt"
    indices, select_W = select_intent(intent_file_path, W)
    print(len(indices), select_W.shape, select_W.device) # 1208 torch.Size([1208, 768]) cuda:2

    indices_random, select_W_random = select_intent_random(intent_file_path, W)
    print(len(indices_random), select_W_random.shape, select_W_random.device) 

    indices_random_no, select_W_random_no = select_intent_random_no(intent_file_path, W)
    print(len(indices_random_no), select_W_random_no.shape)
    pirnt()
    
    if indices_random == indices:
        print("1")
    common_elements = list(set(indices) & set(indices_random))
    print(common_elements, len(common_elements))


    folder = "/data2/jx39280/ICSRec-main/items/beauty/"
    pattern = "encoder_hidden_states_l11_{}_item.pt"
    result = flatten_pt_lists(folder, pattern, num_files=6)

    print("æ€»é•¿åº¦ï¼š", len(result), type(result[0]), result[0].shape, result[1].shape, result[-1].shape) # æ€»é•¿åº¦ï¼š 12101 <class 'torch.Tensor'> <class 'torch.Tensor'>
    # print("å‰ä¸¤é¡¹ï¼š", result[:2])

    # result: List[Tensor] with shape (l, 768)
    tensor_mean = pool_result(result, method='mean')  # shape: (len(result), 768)
    tensor_last = pool_result(result, method='last')  # shape: (len(result), 768)
    print(tensor_mean.shape, tensor_last.shape)
    mean_path = f"/data2/jx39280/ICSRec-main/items/beauty/l11_tenosr_mean.pt"
    last_path = f"/data2/jx39280/ICSRec-main/items/beauty/l11_tenosr_last.pt"
    torch.save(tensor_mean, mean_path)
    torch.save(tensor_last, last_path)
